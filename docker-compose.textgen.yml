version: "3.8"
services:
  base:
    image: ghcr.io/neggles/tensorpods/textgen-webui:latest
    restart: unless-stopped
    command: [ "bash", "-l" ]
    environment:
      # make python print immediately instead of buffering
      PYTHONUNBUFFERED: "1"
      # let safetensors do mmap for faster gpu loading
      SAFETENSORS_FAST_GPU: "1"
      # saves ~1GB of VRAM and speeds up startup, but makes the first run slightly slower
      CUDA_MODULE_LOADING: "lazy" #
    ports:
      - mode: ingress
        target: 7860
        published: 7861
        protocol: tcp
    volumes:
      - type: bind
        source: ./data/models
        target: /work/textgen/models
